---
layout: single
title:  "AWS SAA 준비(Sticky Sessions, Cross Zone Load Balancing, SSL / TLS, Connection Draining, ASG)"
categories: [AWS SAA]
tags: [AWS SAA]
toc: true
author_profile: true
---


## Sticky Sessions

- 로드 밸런서가 특정 클라이언트의 모든 요청을 세션 기간 동안 동일한 대상(EC2 인스턴스 등)으로 계속 보내주는 기능이다.
- 작동 원리: 쿠키 활용
  - 로드 밸런서는 클라이언트가 처음 접속할 때 응답에 특별한 쿠키를 심어서 보낸다. 이후 클라이언트가 다시 요청을 보낼 때 이 쿠키를 함께 보내면, 로드 밸런서는 쿠키 내용을 확인하고 "아, 이 손님은 아까 1번 서버가 담당했었지"라며 다시 1번 서버로 연결해준다.
- 왜 사용할까?
  - 가장 큰 이유는 서버가 로컬(자체 메모리나 디스크)에 세션 정보를 저장하고 있을 때 데이터의 연속성을 보장하기 위해서다.
  - 로그인 상태 유지: 사용자가 A 서버에서 로그인했는데, 다음 요청이 B 서버로 가면 B 서버에는 로그인 정보가 없어 다시 로그인을 요구하게 된다.
  - 장바구니 정보: 쇼핑몰 앱에서 장바구니 데이터를 DB가 아닌 서버 메모리에 임시 저장하는 경우, 동일한 서버로 가야만 물건 목록이 유지된다.
  - 게임/실시간 채팅: 특정 서버와 연결을 맺고 데이터를 주고받아야 하는 실시간 서비스에 필요하다.
- Sticky Session의 종류
  - 기간 기반 쿠키 (Duration-based Cookies)
    - 로드 밸런서가 직접 쿠키를 생성하고 관리한다.
    - 쿠키 이름은 AWSALB(ALB용) 또는 AWSELB(CLB용)로 고정된다.
    - 특정 시간(유효 기간) 동안만 유지되도록 설정할 수 있다.
  - 애플리케이션 기반 쿠키 (Application-based Cookies)
    - 백엔드 애플리케이션(Spring Boot 등)에서 직접 만든 쿠키를 기준으로 한다.
    - 앱에서 필요한 정보를 담은 커스텀 쿠키를 사용할 수 있어 유연성이 높다.
    - 애플리케이션이 지정한 이름의 쿠키를 로드 밸런서가 감시하고 추적한다.
- 장점
  - 기존의 상태 유지형(Stateful) 애플리케이션을 클라우드로 옮길 때 코드 수정 없이 가용성을 확보할 수 있다.
  - 서버 로컬 메모리를 사용하므로 별도의 세션 서버(Redis 등)를 구축하는 비용을 아낄 수 있다.
- 단점 (중요)
  - 부하 불균형: 특정 사용자가 아주 무거운 작업을 수행할 때, 그 사용자가 붙어 있는 서버에만 부하가 쏠려 전체적인 부하 분산 효율이 떨어진다.
  - 확장성 저해: 서버를 늘리거나 줄일 때(Auto Scaling), 스티키 세션이 유지되는 동안은 기존 서버를 쉽게 끄기 어려울 수 있다.
  - 데이터 유실 위험: 만약 해당 서버가 고장 나면 그 서버 메모리에 저장되어 있던 모든 세션 정보가 사라진다.
- `현대적인 아키텍처에서는 Sticky Sessions를 지양한다.`
- 권장 방식
  - 권장 방식: 서버는 아무런 상태를 가지지 않는 Stateless 구조로 설계하고, 세션 정보는 Amazon ElastiCache(Redis)나 DynamoDB 같은 외부 저장소에 따로 보관한다. 이렇게 하면 로드 밸런서가 어느 서버로 트래픽을 보내도 상관없으므로 확장성과 안정성이 극대화된다.


## Cross Zone Load Balancing

- 로드 밸런서 노드가 자신이 속한 가용 영역(AZ)뿐만 아니라, 로드 밸런서에 활성화된 모든 가용 영역에 있는 대상(인스턴스 등)에게 트래픽을 균등하게 분산하는 기능이다.
- 작동 방식
  - 가용 영역 A(AZ-A)에 인스턴스 2대, 가용 영역 B(AZ-B)에 인스턴스 8대가 있다고 가정한다. (총 10대)
  - 비활성화 시
    - 각 가용 영역의 로드 밸런서 노드는 자신이 속한 AZ의 인스턴스에게만 트래픽을 보낸다.
    - 외부 트래픽이 50:50으로 들어온다면 AZ-A: 50%의 트래픽을 2대가 나눔 (대당 25% 부하) / AZ-B: 50%의 트래픽을 8대가 나눔 (대당 6.25% 부하)
    - 결과: 특정 AZ의 인스턴스들에게만 부하가 몰리는 불균형이 발생한다.
  - 활성화 시
    - 각 로드 밸런서 노드는 AZ에 상관없이 전체 10대의 인스턴스를 하나로 보고 트래픽을 보낸다.
    - 외부 트래픽이 50:50으로 들어와도 모든 인스턴스가 동일하게 전체 트래픽의 10%씩 처리한다.
    - 결과: 모든 인스턴스의 부하가 균일하게 유지된다.

| ELB 종류 | 기본 설정 (Default) | 특징 |
|----------|-------------------|------|
| ALB (Application) | 항상 활성화 (Enabled) | 설정을 바꿀 수 없으며, 비용 없이 기본 제공된다. |
| NLB (Network) | 비활성화 (Disabled) | 활성화할 수 있으나, 가용 영역 간 데이터 전송 비용(Inter-AZ Data Transfer)이 발생할 수 있다. |
| GLB (Gateway) | 비활성화 (Disabled) | 필요에 따라 활성화 가능하다. |


## SSL / TLS

- SSL(Secure Sockets Layer)과 그 후속 버전인 TLS(Transport Layer Security)는 웹 브라우저와 웹 서버 간의 통신을 암호화하여 데이터를 안전하게 보호하는 보안 프로토콜이다.
- 오늘날 대부분의 웹사이트에서 사용하는 HTTPS의 S가 바로 이 SSL/TLS가 적용되었음을 의미한다.
- 작동 원리
  - 공개키(Public Key): 누구나 가질 수 있으며 데이터를 암호화할 때 사용한다.
  - 개인키(Private Key): 서버만 안전하게 보관하며, 공개키로 암호화된 데이터를 복호화할 때 사용한다.
  - CA(Certificate Authority): 인증서를 발급해주는 신뢰할 수 있는 제3자 기관(예: DigiCert, GoDaddy, AWS 등)이다.
- AWS에서의 SSL 관리: ACM (AWS Certificate Manager)
  - AWS에서는 ACM이라는 서비스를 통해 SSL/TLS 인증서를 매우 쉽게 발급하고 관리할 수 있다.
  - 자동 갱신: ACM에서 발급받은 공인 인증서는 만료 전 자동으로 갱신된다. (관리 부담 제로)
  - 비용: ALB, CloudFront 등 AWS 서비스에 연결해서 사용하는 공인 인증서는 무료다.
  - 통합: ALB(Application Load Balancer), NLB(Network Load Balancer), CloudFront, API Gateway 등과 바로 연결 가능하다.
- SSL Termination (SSL 오프로딩)
  - 로드 밸런서에서 SSL 인증서를 처리하는 방식이다.
  - 과정: 사용자는 로드 밸런서와 HTTPS(443)로 암호화 통신을 하고, 로드 밸런서는 이를 복호화하여 내부 서버(EC2)에는 HTTP(80)로 전달한다.
  - 장점: EC2 서버가 복잡한 암호화 계산을 하지 않아도 되므로 CPU 부하가 줄어든다.
  - 인증서를 여러 서버에 일일이 설치할 필요 없이 로드 밸런서 한 곳에서만 관리하면 된다.
- SNI (Server Name Indication)
  - 하나의 로드 밸런서에 여러 개의 도메인(예: a.com, b.com)이 연결되어 있을 때, 클라이언트가 어떤 도메인으로 접속했는지에 따라 적절한 인증서를 서버가 골라서 보여주는 기술이다.
  - 특징: ALB와 NLB 모두 지원한다.
  - 효과: 하나의 로드 밸런서(하나의 IP/DNS)로 여러 개의 보안 웹사이트를 운영할 수 있게 해준다.
  - 하나의 HTTPS 리스너에 두 개 이상의 SSL 인증서를 등록하는 순간 자동으로 작동하게 된다.

| 항목 | 핵심 내용 |
|------|-----------|
| 인증서 위치 | 로드 밸런서에 HTTPS 리스너를 추가하고 ACM 인증서를 등록한다. |
| 리전(Region) 주의 | ACM 인증서는 리전별로 생성된다. 서울 리전 ALB를 쓰려면 인증서도 서울 리전 ACM에서 만들어야 한다. (단, CloudFront용 인증서는 무조건 us-east-1에서 만들어야 함) |
| 공인 vs 사설 | 외부 사용자가 접속한다면 Public Certificate, 내부망 전용이라면 Private Certificate를 사용한다. |
| 포트 설정 | HTTPS는 기본 443 포트를 사용한다. |


- **보안 통신을 위해 ACM에서 인증서를 발급받아 ALB 리스너에 등록한다. 로드 밸런서가 암호화를 대신 풀어주는 SSL Termination을 통해 서버 부하를 줄이고, 여러 도메인을 쓸 때는 SNI를 활용한다.**

## Connection Draining

- 로드 밸런서가 어떤 인스턴스를 서비스에서 제외(Deregister)할 때, 현재 처리 중인 요청이 안전하게 완료될 수 있도록 기다려주는 기능이다.
- 작동 원리
  - 인스턴스가 오토 스케일링에 의해 축소되거나, 관리자가 수동으로 제거하려고 할 때 다음과 같은 단계로 진행된다.
  - Deregistration 시작: 인스턴스를 타겟 그룹에서 제거하겠다는 신호가 발생한다.
  - 새 요청 차단: 로드 밸런서는 해당 인스턴스로 새로운 트래픽을 보내는 것을 즉시 중단한다.
  - 대기 상태 (Draining): 하지만 이미 해당 인스턴스에서 처리 중이던 요청들은 연결을 유지한다.
  - 연결 종료: 모든 요청이 완료되거나, 설정된 제한 시간(Timeout)이 지나면 비로소 연결을 완전히 끊고 인스턴스를 종료한다.
- Deregistration Delay(제한 시간) 설정
  - 로드 밸런서는 무한정 기다려줄 수 없으므로 제한 시간을 설정해야 한다.
  - 기본값: 300초 (5분)
  - 설정 범위: 0초 ~ 3,600초 (1시간)
  - 짧은 요청(웹 API 등): 30초 내외면 충분하다.
  - 긴 작업(파일 업로드, 복잡한 쿼리): 작업이 끝날 수 있도록 충분히 길게 설정해야 한다.
  - 0초 설정: 대기 시간 없이 즉시 연결을 끊는다. (사용자 경험에 좋지 않다.)
- 왜 사용할까?
  - 에러 방지: 서버가 갑자기 꺼지면 사용자는 502 Bad Gateway나 504 Gateway Timeout 에러를 보게 된다. Connection Draining은 이를 방지하여 사용자 경험(UX)을 보호한다.
  - 데이터 무결성: 사용자가 결제 요청을 보냈는데 처리 도중 서버가 꺼지면 데이터가 꼬일 수 있다. 처리가 완료될 때까지 기다려줌으로써 비즈니스 로직의 안정성을 높인다.
  - 무중단 배포: 새로운 버전의 소스코드를 배포할 때 구버전 서버를 순차적으로 끌 수 있게 해주어 서비스 중단 없는 배포를 가능하게 한다.


## ASG(Auto Scaling Group)

- 애플리케이션의 부하에 따라 EC2 인스턴스를 자동으로 늘리거나(Scale-out) 줄이는(Scale-in) 서비스다.
- 핵심 목적
  - 부하 대응: 트래픽이 몰릴 때 서버를 늘려 성능을 유지한다.
  - 비용 절감: 트래픽이 적을 때는 불필요한 서버를 꺼서 비용을 아낀다.
  - 자가 치유(Self-healing): 상태가 불량한(Unhealthy) 인스턴스를 감지하면 자동으로 종료하고 새로운 인스턴스를 생성하여 가용성을 유지한다.
- 구성 요소 (세팅 단계)
  - 시작 템플릿 (Launch Template - "무엇을 띄울 것인가?")
    - 인스턴스의 '설계도'다. 예전에는 시작 구성(Launch Configuration)을 썼으나, 현재는 버전 관리가 가능한 시작 템플릿 사용을 권장한다.
    - 포함 내용: AMI(이미지), 인스턴스 타입, 키 페어, 보안 그룹, EBS 설정, 사용자 데이터(User Data) 등
  - ASG 설정 ("어디에, 얼마나 띄울 것인가?")
    - VPC 및 서브넷: 인스턴스가 생성될 네트워크 위치를 지정한다. (보통 여러 가용 영역의 서브넷을 선택하여 고가용성을 확보한다.)
    - 용량 설정 (Capacity)
      - Minimum Size: 최소한 유지해야 할 서버 대수.
      - Maximum Size: 부하가 심해도 넘지 않을 최대 서버 대수.
      - Desired Capacity: 현재 시점에 유지하고 싶은 목표 서버 대수.
- **ASG와 ELB의 협동 과정**
  - 부하 감지: CloudWatch가 CPU 점유율 상승을 감지하고 알람을 울린다.
  - 서버 추가: ASG가 시작 템플릿을 보고 새 EC2를 생성한다.
  - 로드 밸런서 등록: ASG가 새 EC2를 ELB의 대상 그룹(Target Group)에 자동으로 등록한다.
  - 트래픽 분산: 로드 밸런서가 상태 확인(Health Check) 후 정상적인 새 서버로 트래픽을 보내기 시작한다.
- **Cooldown Period(대기 시간)**
  - 서버가 추가되거나 삭제된 후, 시스템이 안정화될 때까지 추가적인 확장/축소 작업을 잠시 멈추는 시간이다. 보통 300초(5분)가 기본값이다.
  - 이유: 서버가 뜨자마자 또 서버를 늘리면, 아직 부하가 분산되기 전이라 서버가 너무 많이 생기는 '오버슈팅'이 발생할 수 있기 때문이다.

### ASG Scaling Policies

- "언제, 어떤 조건에서 인스턴스를 늘리거나 줄일 것인가"를 결정하는 규칙이다. 단순히 서버를 늘리는 것뿐만 아니라, 비용 효율성을 위해 적절히 줄이는 과정까지 포함된다.
- `대상 추적 확장 정책 (Target Tracking Scaling)`
  - 가장 직관적이고 흔히 사용되는 방식이다. 특정 지표(Metric)의 목표치를 설정하면, ASG가 그 수치를 유지하기 위해 알아서 인스턴스 개수를 조절한다.
  - 동작 원리: "평균 CPU 사용률을 50%로 유지해라"라고 설정한다.
  - 특징: 지표가 목표보다 높으면 서버를 늘리고, 낮으면 줄인다. 온도 조절기(Thermostat)와 유사한 방식이다.
  - 주요 지표: ASG 평균 CPU 사용률, 대상 그룹별 ALB 요청 수, 평균 네트워크 유입량 등.
  - 목표 지표를 맞추기 위해 필요한 인스턴스 개수를 수학적으로 계산해서 한 번에 인스턴스 개수를 조정한다.
- `단계별 확장 정책 (Step Scaling)`
  - CloudWatch 알람을 기반으로 하며, 부하의 크기에 따라 단계적으로 대응한다.
  - 동작 원리: CPU 사용률이 50%를 넘으면 인스턴스 1대 추가. / CPU 사용률이 80%를 넘으면 인스턴스 3대 추가.
  - 특징: 부하가 급격히 증가할 때 더 빠르게 대응할 수 있도록 설계되었다. 현재는 단순 확장 정책보다 이 방식을 더 권장한다.
- `단순 확장 정책 (Simple Scaling)`
  - 과거에 주로 사용되던 방식이다. 하나의 알람이 발생하면 정해진 수만큼 늘리거나 줄인다.
  - 동작 원리: "CPU 사용률이 70%가 넘으면 1대 추가"와 같은 단일 규칙이다.
  - 단점: 확장이 일어난 후 쿨다운(Cooldown) 기간이 끝날 때까지는 추가 확장이 불가능하다. 부하가 계속 늘어나는 상황에서는 단계별 확장보다 대응이 늦다.
- `예약된 확장 (Scheduled Scaling)`
  - 트래픽 변화를 시간 단위로 미리 예측할 수 있을 때 사용한다.
  - 동작 원리: "매주 금요일 오후 6시에 인스턴스를 10대로 늘려라"와 같이 특정 시간에 실행되도록 예약한다.
  - 특징: 이벤트(예: 수강 신청, 블랙 프라이데이) 직전에 미리 서버를 준비하여 부하가 걸리기 전부터 가용성을 확보한다.
- `예측 기반 확장 (Predictive Scaling)`
  - AWS의 머신러닝 알고리즘이 과거의 트래픽 패턴을 분석하여 미래의 수요를 예측한다.
  - 동작 원리: 지난 며칠 혹은 몇 주간의 데이터를 학습하여 트래픽이 몰리기 직전에 미리 인스턴스를 늘려둔다.
  - 특징: "예약된 확장"을 수동으로 일일이 설정할 필요 없이 AWS가 자동으로 수행해 준다. 트래픽 패턴이 일정한 대규모 서비스에 유용하다.
