---
layout: single
title:  "AWS SAA 준비(Beanstalk, S3)"
categories: [AWS SAA]
tags: [AWS SAA]
toc: true
author_profile: true
---



## 애플리케이션 인스턴스화

- 클라우드 인프라 운영에서 애플리케이션을 빠르게 인스턴스화(Instantiating applications quickly)하는 것은 오토 스케일링(Auto Scaling) 상황에서 급증하는 트래픽에 대응하거나, 장애 발생 시 빠르게 서비스를 복구하기 위해 매우 중요하다.
- AWS 환경에서 서버가 뜬 후 "준비 완료(Ready)" 상태가 될 때까지의 시간을 줄이는 주요 방법들을 정리한다.
- 골든 이미지 (Golden Image - AMI 사용)
  - 작동 원리: EC2 인스턴스에 운영체제, 런타임(Java, Python 등), 애플리케이션 코드, 종속성 라이브러리, 보안 패치 등을 미리 설치하고 설정한다. 이를 AMI(Amazon Machine Image)로 저장(Baking)해둔다.
  - 장점: 인스턴스가 생성될 때 별도의 설치 과정이 없으므로 부팅 즉시 서비스를 시작할 수 있어 속도가 가장 빠르다.
  - 단점: 코드가 변경될 때마다 매번 새로운 AMI를 만들어야 하는 번거로움이 있다.
- 부트스트래핑 (Bootstrapping - User Data 사용)
  - 작동 원리: 표준 AMI(예: Amazon Linux 2)로 시작하되, EC2 생성 시 사용자 데이터(User Data) 스크립트에 설치 및 설정 명령어를 넣는다.
  - 장점: 코드가 자주 바뀌어도 스크립트만 수정하면 되므로 유연성이 매우 높다.
  - 단점: 서버가 뜰 때마다 매번 라이브러리를 다운로드하고 설치해야 하므로, 실제 요청을 처리하기까지 시간이 오래 걸린다. (네트워크 지연이나 리포지토리 장애에 영향을 받음)
- 하이브리드 방식 (Hybrid Approach)
  - 골든 이미지와 부트스트래핑의 장점을 결합한 방식이다.
  - 작동 원리: 업데이트가 거의 없는 공통적인 것들(OS 패치, 런타임, 대용량 라이브러리)은 골든 이미지로 미리 구워둔다. 이후 인스턴스가 뜰 때 User Data를 통해 최신 애플리케이션 코드나 환경 변수만 내려받는다.
  - 장점: 이미지 관리의 번거로움을 줄이면서도 부트스트래핑보다 훨씬 빠르게 서비스를 시작할 수 있다. 실무에서 가장 권장되는 방식이다.
- 컨테이너화 (Containerization - Docker & Fargate)
  - 가상 머신(VM)보다 가벼운 컨테이너를 사용하는 방법이다.
  - 작동 원리: 애플리케이션을 Docker 이미지로 패키징한다. Amazon ECS나 EKS에서 이 이미지를 실행한다.
  - 속도: EC2 인스턴스를 부팅하는 것보다 컨테이너를 올리는 속도가 수 초 내외로 훨씬 빠르다. 특히 AWS Fargate를 사용하면 기본 인프라 관리를 AWS에 맡기고 컨테이너만 빠르게 실행할 수 있다.
- 서버리스 (Serverless - AWS Lambda)
  - 아예 인스턴스라는 개념을 없애고 코드만 실행하는 방식이다.
  - 특징: 요청이 들어오는 즉시 코드가 실행된다. (밀리초 단위)
  - 한계: 콜드 스타트(Cold Start) 문제가 있을 수 있지만, 프로비저닝된 동시성(Provisioned Concurrency) 설정을 통해 즉각적인 실행을 보장할 수 있다.

## Elastic Beanstalk

- AWS Elastic Beanstalk은 애플리케이션을 AWS 클라우드에 신속하게 배포하고 관리할 수 있게 돕는 PaaS(Platform as a Service) 형태의 서비스다.
- 개발자가 Java(Spring), Docker, Node.js 등으로 작성한 코드를 업로드하면, Elastic Beanstalk이 다음과 같은 인프라 리소스를 자동으로 프로비저닝하고 운영해 준다.
  - 용량 프로비저닝: EC2 인스턴스 생성 및 설정.
  - 부하 분산: 로드 밸런서(ALB) 구성.
  - 오토 스케일링: 트래픽에 따른 인스턴스 증감 조절.
  - 애플리케이션 상태 모니터링: CloudWatch와 연동하여 헬스 체크 수행.
- 구성 요소
  - 애플리케이션 (Application): 논리적인 컨테이너다. 프로젝트 단위라고 생각하면 된다.
  - 애플리케이션 버전 (Application Version): 업로드된 실행 코드의 특정 시점(예: Java의 .jar 파일)을 의미한다. 여러 버전을 올려두고 필요할 때 롤백할 수 있다.
  - 환경 (Environment): 실제로 서비스가 돌아가는 인프라 묶음이다.
    - 웹 서버 환경 (Web Server Tier): 표준 웹 애플리케이션(HTTP 요청 처리).
    - 작업자 환경 (Worker Tier): 백그라운드 작업(SQS 큐 처리 등).
  

## Amazon S3

- AWS에서 제공하는 업계 최고의 확장성, 데이터 가용성, 보안 및 성능을 제공하는 객체 스토리지 서비스다.
- 핵심 개념: 버킷(Buckets)과 객체(Objects)
  - S3는 파일 시스템(폴더 구조)이 아닌 키-값(Key-Value) 구조의 객체 스토리지다.
  - 버킷 (Buckets): 객체를 저장하는 컨테이너다. 버킷 이름은 전 세계 AWS 리전에서 유일(Global Unique)해야 한다. 
  - 객체 (Objects): 저장되는 데이터 본체와 메타데이터의 집합이다.
    - Key: 객체의 이름(경로를 포함한 전체 이름).
    - Value: 실제 데이터 콘텐츠.
    - Metadata: 데이터에 대한 추가 정보(생성일, 크기, 타입 등).

## S3 Security

- 버킷 정책 (Bucket Policies): 버킷 전체 수준에서 권한을 제어한다 (JSON 기반). 특정 IP나 리전에서의 접근만 허용할 때 유용하다.
  - S3 버킷에 직접 부착하여 해당 버킷과 그 안의 객체들에 대한 접근 권한을 제어하는 리소스 기반(Resource-based) 정책이다. JSON 형식으로 작성하며, 누가(Principal), 어떤 작업(Action)을, 어디에(Resource) 할 수 있는지 상세하게 정의한다.
- 예시 : 특정 IP에서만 읽기 허용

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "IPAllow",
      "Effect": "Allow",
      "Principal": "*",
      "Action": "s3:GetObject",
      "Resource": "arn:aws:s3:::my-bucket-name/*",
      "Condition": {
        "IpAddress": {
          "aws:SourceIp": "203.0.113.0/24"
        }
      }
    }
  ]
}
```

- S3 Bucket에 접근하는 3가지 예시
  - 익명의유저 -> S3 Bucket Policy Allows Public Access 필요
  - IAM User -> IAM Policy에서 S3 접근 권한 할당 필요
  - EC2 Instance -> EC2 Instance Role -> IAM permission 사용하여 접근 가능 
- IAM 정책: 사용자나 역할(Role) 단위로 S3 접근 권한을 부여한다.
- 퍼블릭 액세스 차단 (Block Public Access): 실수로 데이터가 외부에 노출되는 것을 방지하기 위해 버킷 또는 계정 수준에서 모든 퍼블릭 접근을 차단한다.
- 암호화 (Encryption): SSE-S3: S3에서 관리하는 키로 암호화.
  - SSE-KMS: AWS KMS의 키로 암호화 (감사 로그 추적 가능).

## S3 Versioning

- 동일한 버킷 내에서 객체의 여러 변종을 유지할 수 있는 수단이다. 이를 활성화하면 실수로 데이터를 덮어쓰거나 삭제했을 때 이전 상태로 쉽게 복구할 수 있어 데이터 보호의 핵심적인 역할을 한다.
- 작동 원리
  - S3 버킷에서 버전 관리를 활성화하면 모든 객체에 고유한 버전 ID(Version ID)가 부여된다.
  - 덮어쓰기 (Overwrite): 기존 객체와 동일한 키로 새로운 파일을 업로드하면, 기존 파일이 삭제되는 것이 아니라 새로운 버전 ID를 가진 객체가 최상단에 쌓이게 된다.
  - 삭제 (Delete): 객체를 삭제하면 실제 데이터가 영구적으로 지워지는 대신, 삭제 마커(Delete Marker)라는 특수한 포인터가 생성되어 최신 버전으로 표시된다.
- 데이터 복구 방법
  - 덮어쓰기 복구: 이전 버전 ID를 지정하여 해당 시점의 데이터를 조회하거나 다시 최신 버전으로 승격시킨다.
  - 삭제 취소: 객체 목록에서 최신 버전으로 설정된 삭제 마커를 삭제하면, 바로 직전 버전의 객체가 다시 노출되면서 복구된다.
- 주요 특징 및 주의 사항
  - 상태 전환: 한 번 활성화하면 '비활성화(Disabled)'할 수 없고, '중지(Suspended)'만 가능하다.
  - 기존 객체: 버전 관리 활성화 이전에 존재하던 객체의 버전 ID는 null로 설정된다.
  - 비용 관리: 모든 버전의 데이터가 물리적 용량을 차지하므로, 스토리지 비용이 증가한다.
  - MFA 삭제: 보안 강화를 위해 다중 인증(MFA)을 거쳐야만 버전을 영구 삭제하거나 상태를 변경하도록 설정할 수 있다.

## S3 Replication

- 서로 다른 S3 버킷 간에 객체를 자동으로, 비동기적으로 복사하는 관리형 기능이다. 데이터의 가용성을 높이거나, 지연 시간을 줄이거나, 규정 준수(Compliance) 요구 사항을 충족하기 위해 사용된다.
- S3 복제의 두 가지 주요 유형
  - CRR (Cross-Region Replication)
  - 대상: 서로 다른 AWS 리전 간 복제
  - 주요 사례: 재해 복구, 전 세계 지연 시간 최소화
  - 특징: 리전 간 데이터 전송 비용 발생
  - SRR (Same-Region Replication)
  - 대상: 동일한 AWS 리전 내 다른 버킷으로 복제
  - 주요 사례: 로그 통합, 테스트/개발 환경 동기화
  - 특징: 동일 리전 내 무료(단, 스토리지 비용 별도)
- 필수 요구 사항
  - 버전 관리(Versioning) 활성화: 소스(Source) 버킷과 대상(Destination) 버킷 모두에서 버전 관리가 켜져 있어야 한다. S3 복제는 객체의 버전을 기반으로 작동하기 때문이다.
  - IAM 역할(Role): S3 서비스가 소스 버킷에서 객체를 읽고 대상 버킷에 쓸 수 있는 권한을 가진 IAM 역할을 부여해야 한다.
- 주요 특징 및 기능
  - 비동기식 복제: 객체가 업로드된 후 즉시 복제되는 것이 아니라, 약간의 시차를 두고 복제된다.
  - 필터링: 전체 버킷을 복제할 수도 있고, 특정 접두사(Prefix)나 태그(Tag)를 기준으로 일부 객체만 선택해서 복제할 수 있다.
  - 기존 객체 복제: 기본적으로 복제 설정 이후의 객체만 복제되지만, 설정을 통해 이미 버킷에 존재하던 기존 객체들도 복제할 수 있다.
  - 삭제 마커 복제: 소스에서 객체를 삭제했을 때 발생하는 '삭제 마커'를 대상 버킷에도 복제할지 여부를 선택할 수 있다.
- 주의 사항
  - **다중 복제(Chained Replication) 불가 버킷 A에서 B로 복제된 객체는 다시 B에서 C로 자동 복제되지 않는다. 즉, 복제된 객체는 다시 복제의 소스가 될 수 없다.**


## S3 Storage Classes

- 데이터의 액세스 빈도와 비용 요구사항에 따라 적절한 클래스를 선택하는 것이 SAA 시험과 실무 설계의 핵심이다.


| 스토리지 클래스 | 설계 목적 | 최소 보관 기간 | 가용성 | 지연 시간 |
|---------------|----------|---------------|--------|-----------|
| Standard | 자주 사용하는 데이터 | 없음 | 99.99% | 밀리초(ms) |
| Intelligent-Tiering | 패턴을 모르는 데이터 | 30일 | 99.9% | 밀리초(ms) |
| Standard-IA | 가끔 쓰는 중요한 데이터 | 30일 | 99.9% | 밀리초(ms) |
| One Zone-IA | 가끔 쓰는 재생성 가능 데이터 | 30일 | 99.5% | 밀리초(ms) |
| Glacier Instant | 거의 안 쓰지만 즉시 필요한 데이터 | 90일 | 99.9% | 밀리초(ms) |
| Glacier Flexible | 아카이빙 (백업용) | 90일 | 99.99% | 분 ~ 시간 |
| Glacier Deep Archive | 장기 보관 (규정 준수) | 180일 | 99.99% | 12 ~ 48시간 |

- S3 Express One Zone
  - S3 Express One Zone은 2023년 말에 출시된 S3의 가장 최신 스토리지 클래스로, 가장 낮은 지연 시간(Latency)과 가장 높은 성능을 제공하도록 설계된 서비스다.
  - 단일 가용 영역(One Zone): 데이터를 여러 가용 영역에 복제하지 않고, 단 하나의 AZ 내부에만 저장한다. 데이터가 물리적으로 가까운 곳에 집중되어 있어 통신 지연을 극단적으로 줄인다.
  - 디렉터리 버킷(Directory Buckets): 기존의 범용(General Purpose) 버킷과 아키텍처가 다르다. 계층적 구조를 통해 초당 수십만 번의 요청을 지연 없이 처리한다.
  - 성능: 기존 S3 Standard보다 읽기/쓰기 성능이 최대 10배 더 빠르다.
  - 요청 비용: 약 50% 저렴 (S3 Standard에 비해)
  - 저장 비용: 상대적으로 높음
- 주요 사용 사례 (Use Cases)
  - 머신러닝(ML) 및 AI 학습: 수백만 개의 작은 학습 데이터를 모델에 빠르게 밀어 넣어야 할 때 병목 현상을 해결한다.
  - 금융 모델링: 대규모 시뮬레이션이나 고빈도 거래 데이터 분석.
  - 고성능 컴퓨팅(HPC): 수천 개의 컴퓨팅 노드가 동시에 동일한 데이터 세트에 접근해야 하는 환경.
  - 실시간 데이터 분석: 스트리밍 데이터를 즉시 수집하고 쿼리해야 하는 경우.                       

## S3 Lifecycle Policies

- 데이터가 생성된 후 시간이 흐름에 따라 더 저렴한 스토리지 클래스로 자동으로 이동하도록 설정할 수 있다.
- Transition 액션: 일정 기간(예: 30일)이 지나면 Standard에서 Standard-IA로, 다시 60일 뒤에 Glacier로 옮기는 설정이다.
- Expiration 액션: 특정 기간이 지난 데이터를 자동으로 영구 삭제하도록 설정한다.

## S3 Requester Pays 

- S3 버킷의 소유자가 아닌, 데이터를 요청하는 사람(요청자)이 데이터 전송 비용과 요청 비용을 부담하게 하는 기능이다.
- 일반적으로 S3의 데이터 전송 비용(Data Transfer Out)은 버킷 소유자가 지불하지만, 대용량 데이터를 외부와 공유할 때 소유자의 비용 부담이 지나치게 커지는 것을 방지하기 위해 사용된다.
- 필수 요구 사항 및 특징
  - 인증 필수: 요청자가 누구인지 식별해야 비용을 청구할 수 있으므로, 익명(Anonymous) 접근은 허용되지 않는다. 요청자는 반드시 AWS 계정 인증을 거쳐야 한다.
  - 요청 시 명시: 요청자는 자신이 비용을 지불할 의사가 있음을 명시해야 한다. HTTP 헤더에 x-amz-request-payer: requester를 포함하거나, SDK/CLI 옵션에서 이를 활성화해야 한다.
  - 버킷 단위 설정: 이 기능은 객체 단위가 아닌 버킷 단위로 설정된다.


## S3 Event Notifications 

- S3 버킷 내에서 특정 사건(파일 업로드, 삭제 등)이 발생했을 때 이를 감지하여 다른 AWS 서비스로 알림을 보내는 기능이다.
- 작동 원리
  - 버킷에 객체가 생성되거나 삭제되는 등의 상태 변화가 생기면 S3는 미리 정의된 대상으로 메시지를 발행한다. 이때 접두사(Prefix)나 접미사(Suffix) 필터링을 사용하여 특정 폴더 내의 파일이나 특정 확장자(.jpg 등)에 대해서만 알림을 보내도록 세밀하게 설정할 수 있다.
- 알림 대상

| 대상 서비스 | 특징 | 주요 사례 |
|------------|------|----------|
| AWS Lambda | 코드를 즉시 실행하는 서버리스 방식이다 | 이미지 업로드 시 썸네일 자동 생성, 로그 분석 |
| Amazon SQS | 메시지를 큐에 저장하여 순차적으로 처리한다 | 대량의 작업을 비동기적으로 처리할 때 사용 |
| Amazon SNS | 여러 구독자에게 동시에 알림을 뿌린다 (Fan-out) | 이메일 발송, 여러 Lambda 함수 동시 실행 |


- Amazon EventBridge와의 연동
  - 최근에는 S3 설정을 직접 건드리기보다 Amazon EventBridge를 통해 이벤트를 처리하는 방식이 권장되기도 한다.
  - 장점: S3뿐만 아니라 수십 가지의 다른 AWS 서비스 이벤트를 한곳에서 관리할 수 있다.
  - 세밀한 규칙: 특정 조건에 맞는 이벤트만 골라내어 더 다양한 대상(Step Functions, Kinesis 등)으로 보낼 수 있다.
  - 과거 방식과의 차이: 기존 S3 알림은 설정이 버킷 당 제한적이지만, EventBridge는 더 유연한 라우팅이 가능하다.
- 주의사항
  - IAM 권한: S3가 해당 서비스(SNS, SQS, Lambda)에 메시지를 보낼 수 있도록 리소스 기반 정책(Resource-based Policy)을 반드시 설정해야 한다. (예: SNS Access Policy에서 S3의 접근을 허용해야 함)

## S3 Performance

- 기본 요청 성능 (Request Rates)
  - Amazon S3는 기본적으로 매우 높은 요청 속도를 자동으로 지원한다. 버킷 내의 접두사(Prefix)당 다음과 같은 초당 요청 제한을 가진다.
  - Prefix : 
  - 쓰기 (PUT/COPY/POST/DELETE): 초당 3,500회
  - 읽기 (GET/HEAD): 초당 5,500회
  - 이 수치는 단일 버킷 전체가 아니라 각 접두사마다 적용되는 성능이다. 따라서 트래픽이 꾸준히 증가하면 S3가 내부적으로 파티셔닝을 통해 성능을 자동으로 확장한다.
- 데이터 전송 최적화 기법
  - 대용량 파일을 다루거나 지연 시간을 줄여야 할 때 사용하는 실무 기법들이다.
  - 멀티파트 업로드 (Multipart Upload)
    - 파일을 여러 조각으로 나누어 병렬로 업로드한다.
    - **100MB 이상 대용량 파일에 권장되며**, 전송 속도 향상과 장애 복구(실패한 조각만 재전송)에 매우 유리하다.
  - 바이트 범위 페치 (Byte-Range Fetches)
    - 객체의 특정 부분(예: 1~100바이트)만 요청하는 기능이다.
    - 파일의 헤더만 읽어야 하거나, 여러 연결을 동시에 맺어 파일의 서로 다른 부분을 병렬로 다운로드할 때 성능을 극대화할 수 있다.
- 네트워크 및 쿼리 최적화

| 기능 | 특징 | 주요 용도 |
|-----|------|----------|
| S3 Transfer Acceleration | AWS 엣지 로케이션을 거쳐 최적화된 경로로 전송한다 | 국가 간 또는 대륙 간 대용량 데이터 전송 가속 |
| S3 Select | S3 서버 측에서 SQL로 필요한 데이터만 필터링해서 보낸다 | 전송 데이터량 및 클라이언트 CPU 부하 감소 |
| S3 Express One Zone | 1ms 미만의 일관된 지연 시간을 제공하는 전용 스토리지 | 머신러닝(ML), 실시간 데이터 분석 |


- 성능 설계 시 주의사항 
  - 동일 리전 원칙: 지연 시간을 줄이는 가장 확실한 방법은 데이터를 처리하는 EC2 인스턴스와 S3 버킷을 같은 리전에 두는 것이다.

## S3 Batch Operation

- 수백만 개에서 수십억 개의 S3 객체에 대해 대규모 일괄 작업을 수행할 수 있게 해주는 관리형 서비스다.
- 작동 원리
  - S3 Batch Operations는 크게 세 단계로 작동한다.
  - 매니페스트(Manifest) 작성: 처리해야 할 객체들의 목록을 S3에 알려준다. 보통 S3 Inventory 리포트를 그대로 쓰거나, 직접 작성한 CSV 파일을 사용한다.
  - 작업(Job) 생성: "이 목록에 있는 파일들을 대상으로 무엇을 할 것인가?"를 정의한다. 이때 작업에 필요한 권한을 담은 IAM Role을 함께 설정한다.
  - 실행 및 보고: AWS가 백그라운드에서 작업을 수행하며, 작업이 끝나면 성공과 실패 여부가 담긴 완료 보고서(Completion Report)를 생성해 준다.
- 주요 작업
  - 복사 (Copy): 수억 개의 객체를 다른 버킷(다른 리전이나 다른 계정 포함)으로 한꺼번에 복사한다.
  - 태그 교체/추가 (Replace/Add Tags): 수명 주기 정책이나 보안 정책을 적용하기 위해 대량의 객체에 일괄적으로 태그를 붙인다.
  - Glacier 복원 (Restore): 아카이브된 수많은 데이터를 한꺼번에 활성 상태로 되돌린다.
  - ACL 변경: 객체의 접근 권한 설정을 대규모로 수정한다.
  - Lambda 함수 실행: 가장 강력한 기능이다. 각 객체에 대해 사용자 정의 로직(데이터 변환, 분석, 외부 API 호출 등)을 수행할 수 있다.

## S3 Storage Lens

- AWS 계정 또는 조직 전체의 S3 사용 현황과 활동을 한눈에 파악할 수 있게 해주는 클라우드 스토리지 분석 솔루션이다.
- 핵심 기능: 무엇을 볼 수 있는가?
  - 단일 버킷이 아니라, 조직 전체(Multi-account) 및 모든 리전(Multi-region)에 걸쳐 분산된 데이터를 하나의 대시보드에서 분석한다.
  - 요약 메트릭: 전체 저장 용량, 객체 수, 평균 객체 크기 등을 확인한다.
  - 비용 최적화: 불필요한 버전 데이터, 완료되지 않은 멀티파트 업로드, 거의 사용되지 않는 데이터 등을 찾아내어 비용 절감 포인트를 짚어준다.
  - 보안 및 보호: 암호화되지 않은 버킷, 퍼블릭 액세스가 허용된 버킷, 복제 설정이 없는 버킷 등을 식별하여 거버넌스를 강화한다.
  - 활동 분석: 객체에 대한 요청(GET, PUT 등) 패턴을 분석하여 트래픽 변화를 감지한다.

- 요금제 비교 (기본 vs 고급)

| 구분 | 기본 (Free) | 고급 (Advanced - 유료) |
|-----|-------------|------------------------|
| 활성화 | 자동으로 활성화됨 | 사용자가 대시보드 생성 시 선택 |
| 메트릭 수 | 28개 (사용량 중심) | 60개 이상 (활동, 보안, 성능 포함) |
| 데이터 보존 | 14일 | 15개월 (장기 추세 분석 가능) |
| 상세도 | 버킷 수준까지 | 접두사(Prefix) 수준까지 |
| 추천 기능 | 기본 제공 | 고급 최적화 및 보안 추천 제공 |

- 설계 조언
  - 데이터 내보내기: 대시보드에서 보는 것에 그치지 않고, 분석 데이터를 매일 S3 버킷으로 내보내도록 설정할 수 있다. 이 데이터를 Amazon Athena나 QuickSight로 연결하면 더 깊이 있는 커스텀 분석이 가능하다.
  - 조직 단위 관리: 개별 계정에서 대시보드를 보는 것도 좋지만, AWS Organizations와 연동하여 관리 계정에서 전체 계정의 데이터를 통합 조회하는 설계를 권장한다.

- 주요 사용 시나리오
  - 비용 절감: "어떤 버킷에서 '불완전한 멀티파트 업로드'가 용량을 잡아먹고 있는가?"를 찾아내어 즉시 정리한다.
  - 보안 감사: "우리 조직의 모든 버킷 중 SSE-KMS 암호화가 적용되지 않은 곳은 어디인가?"를 리스트로 뽑아 보안 정책을 적용한다.
  - 성능 모니터링: "특정 리전에서 갑자기 403 Forbidden 에러나 503 Slow Down 에러가 급증하고 있지 않은가?"를 확인하여 장애에 대응한다.


## S3 Encryption

- Amazon S3에서 데이터를 보호하는 방법은 크게 `전송 중 암호화(Encryption in Transit)와 저장 시 암호화(Encryption at Rest)로 나뉜다.`
- **전송 중 암호화**
  - 데이터가 클라이언트와 S3 사이를 이동할 때 가로채기 공격으로부터 보호하는 방식이다.
  - HTTPS(TLS): S3는 기본적으로 HTTPS 엔드포인트를 제공하여 전송 구간을 암호화한다.
  - 정책 강제: Bucket Policy에서 aws:SecureTransport 같은 조건을 사용하여 조건에 맞지 않는 접근을 차단하고 조건에 맞는 접근만 허용하도록 강제할 수 있다. Bucket Policy가 우선이다. (Default는 SSE-S3 / HTTP 접근을 차단하고 HTTPS만 허용하도록 강제 / 특정 암호화 방식(예: SSE-KMS)이 아니면 업로드를 거부(Deny)하는 정책을 세워 전사적인 보안 표준을 강제 등)
- **저장 시 암호화**
  - 데이터가 S3 버킷 내의 디스크에 저장될 때 암호화되는 방식이다. 크게 서버 측 암호화(SSE)와 클라이언트 측 암호화로 구분된다.
  - 서버 측 암호화 (Server-Side Encryption, SSE)
    - SSE-S3 : S3 관리형 키 사용, AWS가 키 관리, 가장 쉽고 비용이 들지않음. AES-256 알고리즘 사용
    - SSE-KMS : AWS KMS 관리형 키 사용, AWS + 사용자가 키 관리, 키 사용 기록이 CloudTrail에 남음. 키 교체(Rotation) 및 권한 제어 가능.
    - SSE-C : 클라이언트가 제공하는 키 사용, 사용자가 키 관리, 암호화는 AWS가 하지만, 사용자가 직접 키를 관리하고 전송해야 함. AWS는 키를 저장하지 않음.
  - 클라이언트 측 암호화 (Client-Side Encryption)
    - 데이터를 S3로 보내기 전에 사용자 환경(애플리케이션)에서 직접 암호화하는 방식이다.
    - 특징: AWS는 데이터가 암호화된 상태로만 받기 때문에 원본 내용을 알 수 없다.
    - 라이브러리: 주로 Amazon S3 Encryption Client(Java, Go 등)를 사용하여 구현한다.
- S3 Bucket Keys (SSE-KMS 비용 최적화)
  - 작동 원리: 버킷 수준에서 임시 키를 생성하여 일정 기간 재사용함으로써 KMS 호출 횟수를 획기적으로 줄여준다.
  - 효과: KMS 비용을 최대 99%까지 절감할 수 있으므로, 대규모 데이터 세트에는 필수적으로 활성화한다.

## S3 CORS (Cross-Origin Resource Sharing) 

- 한 출처(Origin)에서 실행 중인 웹 애플리케이션이 다른 출처의 자원에 접근할 수 있는 권한을 브라우저로부터 부여받는 메커니즘이다.
- "출처(Origin)"의 정의
  - 브라우저가 '출처'가 같다고 판단하려면 다음 세 가지 요소가 모두 일치해야 한다.
  - Protocol: http vs https
  - Host: example.com vs api.example.com
  - Port: 80 vs 443 vs 3000
  - 이 중 하나라도 다르면 Cross-Origin이 된다.
- CORS 작동 원리
  - 브라우저가 다른 출처로 HTTP 요청을 보낼 때, 다음과 같은 과정을 거친다.
    - 예비 요청 (Preflight Request)
    - 가장 흔한 방식으로, 실제 요청을 보내기 전에 브라우저가 OPTIONS 메서드를 사용하여 서버에 '안전한지' 먼저 물어본다.
    - 헤더: Origin (요청을 보내는 곳), Access-Control-Request-Method (사용할 메서드) 등을 보낸다.
    - 응답: 서버는 Access-Control-Allow-Origin (허용된 출처) 등을 포함하여 응답한다. 만약 이 응답에 요청한 출처가 포함되어 있지 않으면 브라우저는 에러를 발생시킨다. 
- Amazon S3에서의 CORS 설정
  - S3 버킷에 정적 웹 사이트를 호스팅하거나 다른 도메인에서 S3의 파일을 자바스크립트로 호출할 때(예: 웹 폰트, AJAX 요청 등) CORS 설정이 필수적이다.
  - 설정 방식: 버킷의 [권한] 탭에서 JSON 형식으로 작성한다.
  - AllowedOrigins: 허용할 도메인 (예: ["https://www.example.com"])
  - AllowedMethods: 허용할 HTTP 메서드 (예: ["GET", "POST"])
  - AllowedHeaders: 허용할 요청 헤더
  - ExposeHeaders: 브라우저가 접근할 수 있는 응답 헤더

```json
[
    {
        "AllowedHeaders": ["*"],
        "AllowedMethods": ["GET", "HEAD"],
        "AllowedOrigins": ["https://mirae-tech.com"],
        "ExposeHeaders": []
    }
]
```
    
- 브라우저 전용 에러: CORS는 서버 간의 통신이 아니라 브라우저의 보안 기능이다. 따라서 curl이나 Postman으로 요청했을 때는 잘 되는데 브라우저에서만 안 된다면 99% CORS 문제다.
- 와일드카드(*) 주의: 테스트 시 AllowedOrigins에 *을 쓰면 편하지만, 보안상 위험하므로 운영 환경에서는 반드시 특정 도메인을 명시해야 한다. 특히 인증 정보(Cookie 등)를 포함한 요청에서는 와일드카드를 사용할 수 없다.

- 예시 : www.example.com 에서 파일을 호스팅하는데, 여기의 index.html 파일에서 www.api.com 의 리소스에 접근을 해야한다. 그렇다면 CORS 설정으로 www.api.com 에서 www.example.com 의 요청을 허용해주어야 한다.
  - 요청: www.example.com의 브라우저가 www.api.com으로 데이터를 달라고 요청을 보낸다. 이때 헤더에 Origin: https://www.example.com을 실어 보낸다.
  - 응답: www.api.com 서버는 응답과 함께 Access-Control-Allow-Origin: https://www.example.com이라는 허가증(헤더)을 보낸다.
  - 검사: 브라우저는 www.api.com이 보낸 허가증에 요청한 주소(www.example.com)가 있는지 확인한다.
  - 결과: 허가증이 있으면 데이터를 통과시키고, 없으면 보안 에러를 내며 데이터를 차단한다.

## S3 Access Logs

- S3 버킷에 수행된 모든 요청에 대한 상세한 기록을 생성하는 기능이다. 보안 감사, 규정 준수 확인, 그리고 비용 분석이나 트러블슈팅을 위해 필수적으로 사용되는 기능이다.
- 작동 원리
  - 액세스 로깅을 활성화하면 S3는 해당 버킷에서 발생하는 요청을 수집하여 로그 파일 형태로 지정된 다른 버킷에 저장한다.
  - 소스 버킷(Source Bucket): 액세스 로그를 모니터링할 대상 버킷이다.
  - 대상 버킷(Target Bucket): 생성된 로그 파일이 저장될 버킷이다.
- 주요 특징 및 주의 사항
  - 최선 노력 방식 (Best Effort Delivery)
    - 로그 전달은 '최선 노력' 방식으로 이루어진다. 즉, 대부분의 로그는 몇 시간 내에 전달되지만, 드물게 로그가 누락되거나 지연될 수 있음을 감안해야 한다. 완전한 무결성이 필요한 경우 CloudTrail 데이터 이벤트 사용을 검토해야 한다.
  - 비용
    - 로그 파일 저장에 따른 S3 스토리지 비용이 발생한다. 하지만 로그를 수집하고 전달하는 과정 자체에는 추가 비용이 들지 않는다.
  - 무한 루프 주의
    - 대상 버킷을 소스 버킷과 동일하게 설정하면 안 된다. > 로그가 생성되어 버킷에 저장되는 행위 자체가 다시 '로그'를 남기게 되어, 기하급수적으로 로그가 쌓이는 무한 루프가 발생하고 엄청난 비용이 청구될 수 있다.
- 로그 분석 방법
  - 로그는 원시 텍스트 파일 형태이므로 사람이 직접 읽기는 어렵다. 주로 다음과 같은 도구를 결합하여 분석한다.
  - Amazon Athena: S3에 저장된 로그 파일을 SQL 문으로 직접 쿼리하여 분석할 때 가장 많이 사용된다.
  - S3 수명 주기 정책: 로그 데이터가 무한정 쌓이지 않도록 일정 기간 후 자동으로 삭제하거나 저렴한 스토리지(Glacier)로 옮기도록 설정한다.

  
| 비교 항목 | S3 서버 액세스 로그 | CloudTrail 데이터 이벤트 |
|---------|------------------|------------------------|
| 상세 수준 | 매우 상세함 (HTTP 상태 코드 등 포함) | API 호출 중심의 기록 |
| 전달 속도 | 수 시간 내 (지연 가능성 있음) | 실시간에 가까움 (보통 15분 이내) |
| 비용 | 무료 (스토리지 비용만 부담) | 유료 (이벤트 당 비용 발생) |
| 용도 | 상세한 트래픽 분석, 로그 데이터 보관 | 보안 감사, 실시간 규정 준수 모니터링 |


## S3 Presigned URLs

- 보안상 비공개(Private)로 설정된 S3 객체에 대해, 특정 시간 동안만 유효한 임시 접근 권한을 부여하는 URL이다.
- 사용자에게 안전하게 파일을 다운로드하게 하거나, 서버를 거치지 않고 S3에 직접 파일을 업로드하게 할 때 필수적인 도구다.
- 주요 특징
  - 권한 상속: URL을 생성한 사람의 권한을 그대로 따른다. 만약 생성자가 해당 파일에 대한 읽기 권한이 없다면, URL을 만들어도 작동하지 않는다.
  - 만료 시간 설정: 최소 1초에서 최대 7일까지 설정할 수 있다. (사용하는 자격 증명 방식에 따라 상한선이 다를 수 있다.)
  - 모든 작업 지원: 가장 흔한 GET(다운로드) 외에도 PUT(업로드)용 Presigned URL을 만들어 클라이언트가 서버를 거치지 않고 직접 S3에 대용량 파일을 올리게 할 수 있다.
- 왜 사용하는가?

| 시나리오 | 기존 방식의 문제점 | Presigned URL의 해결책 |
|--------|------------------|----------------------|
| 유료 콘텐츠 제공 | 파일을 퍼블릭으로 설정하면 누구나 접근 가능함. | 인증된 사용자에게만 10분짜리 전용 링크 발급 |
| 대용량 파일 업로드 | 서버를 거치면 서버의 네트워크 대역폭과 CPU 소모가 심함. | S3로 직접 업로드하게 하여 서버 부하 제로화 |
| 임시 공유 | IAM 유저를 매번 만들어줄 수 없음. | 임시 URL만 전달하여 보안성 유지 |

- 실무에서는 CloudFront와 S3를 함께 사용하는 경우가 많다. 이때 S3의 Presigned URL 대신 CloudFront Presigned URL을 사용할 수도 있다.
- S3 Presigned URL: 단일 객체에 대한 임시 접근.
- CloudFront Presigned URL: 전 세계 엣지 로케이션을 통한 가속 및 커스텀 도메인 사용 가능. 여러 파일에 대한 접근 제어에 더 유리함.

## S3 Object Lock

- Amazon S3 Object Lock은 객체가 지정된 시간 동안 또는 무기한으로 삭제되거나 덮어쓰기 되는 것을 방지하는 기능이다. 이는 데이터 무결성을 유지하고 WORM(Write Once, Read Many) 보호를 구현하는 데 사용된다.
- 필수 조건: 버전 관리(Versioning)
  - S3 Object Lock을 사용하려면 해당 버킷에 버전 관리(Versioning)가 반드시 활성화되어 있어야 한다. Object Lock은 객체의 특정 버전을 보호하는 방식으로 작동하기 때문이다.

- 두 가지 보존 모드 (Retention Modes)
  - Object Lock에는 권한 수준에 따라 두 가지 모드가 존재한다. 이 차이를 이해하는 것이 SAA 시험과 실무 설계의 핵심이다.
  - 거버넌스 모드 (Governance Mode)
    - 특징: 특수 권한(s3:BypassGovernanceRetention)이 없는 사용자는 객체를 삭제하거나 설정을 변경할 수 없다.
    - 용도: 실수로 인한 삭제를 방지하면서도, 관리자(Root 계정이나 특정 관리자)는 필요할 때 데이터를 삭제할 수 있도록 유연성을 두는 경우에 사용한다.
  - 규정 준수 모드 (Compliance Mode)
    - 특징: AWS 루트 사용자를 포함한 그 누구도 보존 기간이 끝나기 전까지는 객체를 삭제하거나 모드를 변경할 수 없다. 보존 기간을 단축하는 것도 불가능하다.
    - 용도: 법적 규제 준수가 필수적이어서 그 어떤 상황에서도 데이터가 변조되거나 삭제되면 안 될 때 사용한다.
- 보존 기간 vs 법적 보존 (Legal Hold)
  - 데이터를 묶어두는 방식에는 '시간 기반'과 '상태 기반'이 있다.
  - 보존 기간 (Retention Period): 객체에 유효 기간을 설정한다. (예: 2028년 12월 31일까지 보호). 기간이 지나면 보호가 해제된다.
  - 법적 보존 (Legal Hold): 만료 날짜가 없다. 명시적으로 해제할 때까지 객체가 보호된다. s3:PutObjectLegalHold 권한이 있는 사용자가 자유롭게 설정하고 해제할 수 있으며, 보존 기간 설정 여부와 상관없이 독립적으로 작동한다.

## S3 Access Points

- 공유 데이터 세트에 대한 데이터 접근 관리를 대규모로 단순화하기 위해 도입된 기능이다.
- 왜 Access Points가 필요한가?
  - 기존의 방식인 단일 버킷 정책에는 몇 가지 한계가 있다.
  - 크기 제한: 버킷 정책은 최대 20KB까지만 작성이 가능하다. 사용자가 많아지면 이 용량이 부족해진다.
  - 복잡성: 수백 명의 사용자에 대한 Allow와 Deny 규칙이 한곳에 섞여 있으면, 실수로 권한을 잘못 건드렸을 때 전체 시스템에 영향을 줄 위험이 크다.
- 핵심 특징
  - 독립된 액세스 포인트 정책 (Access Point Policy)
    - 각 액세스 포인트는 자신만의 IAM 정책을 가질 수 있다. 이를 통해 특정 액세스 포인트를 통해서 들어오는 요청에 대해서만 세밀하게 권한을 부여할 수 있다.
  - 전용 호스트 이름 (Unique Hostnames)
    - 각 액세스 포인트는 고유한 DNS 이름을 가진다. 애플리케이션은 버킷 이름 대신 이 액세스 포인트의 호스트 이름을 사용하여 데이터에 접근한다.
  - VPC 전용 액세스 포인트 (VPC Access Points)
    - 인터넷을 거치지 않고 오직 특정 VPC 내부에서만 접근할 수 있도록 네트워크 경로를 제한할 수 있다. 이는 보안이 중요한 사내 데이터 관리 시 매우 유용하다.

## S3 Object Lambda 

- S3에서 데이터를 가져올 때(GET 요청), 사용자가 작성한 Lambda 함수를 거쳐 데이터를 실시간으로 가공하여 반환하는 기능이다.
- 기존에는 동일한 원본 데이터를 용도에 맞게 여러 버전(예: 보안 마스킹 된 버전, 압축된 버전 등)으로 미리 만들어 저장해야 했지만, Object Lambda를 사용하면 원본은 하나만 두고 요청 시점에만 필요한 형태로 변환할 수 있다.
- 구성 요소 (Components)
  - Object Lambda를 구축하기 위해서는 다음 요소들이 체인처럼 연결되어야 한다.
  - S3 버킷: 데이터 원본이 저장된 실제 저장소.
  - 표준 S3 액세스 포인트 (Standard Access Point): Lambda가 원본 데이터에 접근하기 위한 통로.
  - Lambda 함수: 데이터를 변환하는 코드가 담긴 본체.
  - S3 Object Lambda 액세스 포인트: 사용자가 최종적으로 접근하게 될 지점.


![구조](/assets/images/Object-Lambda.png)